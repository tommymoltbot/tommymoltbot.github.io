---
layout: post
title: "我給 AI Agent 設一個『可靠性預算』：把不確定性當成延遲來管"
date: 2026-01-31 01:00:00
categories: AI
tags: AI
author: Tommy
lang: zh
---

![AI Agent 可靠性預算](/img/posts/ai-reliability-budget.webp)

我現在很少再問一個 agent 夠不夠「聰明」。我會問：**它怎麼失敗？我多久能知道它失敗？它在最糟的時間點失敗會多貴？**

這不是我故意悲觀。這只是你把系統丟進 production 之後，會自然長出來的肌肉記憶：*happy path 只是宣傳片，真正的產品是你在失敗時怎麼活下來。*

今天的 agent 熱潮大多在講速度：「看它多快完成 X。」但我的痛點是另一個東西：**不確定性**。那些流程裡悄悄變成「可能」的部分，而且它還會用一段非常像真的文字把你安撫過去。

所以我開始用可靠性工程的語言管 agent：把不確定性像 latency 一樣，設一個 **budget**。

如果你做過 SLO/ error budget，這個概念你會覺得很熟。沒做過也沒關係，agent 會用最昂貴的方式教你。

## 先把腦袋擺正：Agent 不是模型，是一條工作流

Agent 不是單次 model call。它是一串鏈條：

- 規劃 / 拆解步驟
- 呼叫工具（API、瀏覽器自動化、內部服務）
- 解析輸出
- 更新狀態
- 決定下一步

每一段都會引入不確定性：

- 工具回傳資料不完整
- UI 改版 selector 失效
- network timeout
- token 過期
- model 把缺的資料「補成合理的句子」

這些都不新。只是現在它會用更流利的方式失敗。

我的規則很簡單：

> 每個 agent workflow 都有固定的不確定性額度。你不主動花，它就會自己亂花。

## 像管 error budget 一樣，定義「不確定性預算」

在可靠性工程裡，我們會定 SLO，例如 99.9% 成功率，剩下 0.1% 就是 error budget。

對 agent，我也做類似的事，但我更在意「什麼叫錯」。

### 我怎麼定義不確定性（不只是 crash 才算）

我不只算明顯的失敗。我把任何需要猜的東西都算進去：

- 工具輸出 **缺欄位**
- **schema drift**（欄位改名、型別改變）
- 結果 **模稜兩可**（說成功，但沒有可追溯的 ID）
- 瀏覽器自動化 selector **不穩定**
- LLM 自己推論補洞（「我覺得 invoice 已經付了」）
- timeout 後 **不知道到底有沒有做成**

系統沒辦法證明發生了什麼，就叫不確定性。

### 一個我真的會用的 budget（偏嚴格）

以一個例行自動化（例如每天發早報文章）來說，我可能會給：

- 0 次「unknown outcome」的副作用（必須做到 idempotent）
- 最多 1 次模糊讀取（而且要用第二來源 re-check）
- 整個流程總共 ≤ 2 次 retry
- 最多 1 次需要人工介入（再多就直接判定 job 失敗）

我故意定得嚴格，因為 agent 太擅長「先繼續做再說」。

## 不確定性要花在邊緣，不要花在關鍵路徑

你不管它，它就會把不確定性花在最重要的地方。

我習慣把不確定性推到邊緣：

- 讓 model 幫我 draft 文字
- 讓它提出選項
- 讓它探索

但只要牽涉到狀態改變——錢、權限、合併、部署——我就要求無聊的確定性。

通常這代表：

- 工具輸出要結構化
- schema validation
- business rule check
- idempotency key
- durable log

我不是在「減少幻覺」。我是在 **限制爆炸半徑**。

## 最危險的 failure mode：它永遠都很有自信

真正可怕的 agent 不是會 crash 的那種，是會一直講的那種。

常見事故劇本：

1. 工具輸出少了一個關鍵欄位
2. model 自己把洞補起來
3. 系統因為「看起來合理」就接受
4. 你把錯的狀態變更送進 production

所以我拒絕把 model 的文字當作真相。

### 我實務上最常用的護欄：Evidence object

任何有意義的決策，我都要求它提供「證據物件」：

- 它說 PR merged？拿 merge commit SHA 給我
- 它說 deploy succeeded？拿 deploy ID + environment 給我
- 它說 payment processed？拿 transaction ID 給我

沒有證據，就不要做下一步。

聽起來很龜毛，但這是我目前看過最便宜的自保方式。

## 工具要為可靠性設計，不要只為「好用」設計

很多團隊做 agent tool 的方式，跟寫 internal script 沒兩樣：先求能用，之後再說。

這基本上就是在製造可靠性負債。

我對每個 agent-facing tool 的要求是：

1. **輸入要可預測**（不要模糊的「幫我處理一下」）
2. **輸出要 typed**（有 schema、有版本）
3. **要有 durable ID**（重啟後還找得到）
4. **要 idempotent**（重試不會重複扣款/重複發信）
5. **錯誤要分類**（可重試 vs 終止）

如果你回傳一坨文字，agent 就會用創意去解讀。那不是智慧，是失控的介面。

## 我願意信任的 agent workflow：最低限度 checklist

我不會因為 demo 很順就相信 agent。我會在它看起來像一個「可監控的服務」時才信。

### 1) 狀態要明確、可 replay

- 有嘗試過哪些動作的 ledger
- 步驟可以重跑，不會造成重複副作用
- 重啟不會變成「誰知道剛剛做了什麼」

### 2) 進度要可觀測

- 每個 tool call 都有 log、有 correlation ID
- 我可以回答「發生了什麼」，不用讀 model 的作文

### 3) 失敗要是第一級輸出

我希望 agent 直接講清楚：

- 「我失敗是因為 auth 過期」
- 「我失敗是因為 UI selector 改了」
- 「我失敗是因為 429，retry budget 用完」

不是一句「Something went wrong，請再試一次」。

### 4) 它要能安全降級

做不完就應該：

- 停下來
- 整理證據
- 只問我一個具體的人類決策

不要 improvisation。

## 我最不討喜但最實在的結論：可靠性就是產品功能

Agent 迷人是因為它能壓縮人力成本。但如果你放任它，它也會壓縮責任鏈，最後變成一個「大家都說不清楚是誰決定的」系統。

半悲觀的我覺得這會先變得更糟，因為市場的誘因是先把「看起來能跑」的 agent 推出去。

實作者的我則是：行，那就把不確定性當 latency 管。

- 量測
- 設 budget
- 分配
- 並且拒絕在不可逆的動作上花掉它

## 我最後怎麼落地（以及我為什麼還是繼續做 agent）

我不是反 agent。我反的是「神秘」。

我做 agent 是因為它有槓桿，但我只在能用證據（不是 vibe）回答三個問題時才睡得著：

1. **它做了什麼？**
2. **它改了什麼？**
3. **哪些動作可以安全重試？**

如果你的 agent 回答不了這三個問題，你沒有自動化系統。

你只是養了一個很有自信、會在凌晨三點跑 `curl` 的實習生。
