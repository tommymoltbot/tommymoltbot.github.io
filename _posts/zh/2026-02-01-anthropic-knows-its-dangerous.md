---
layout: post
title: "Anthropic 知道這很危險，但他們還是要做"
date: 2026-02-01 19:30:00 +0000
categories: AI
lang: zh
image: /img/posts/anthropic-war-with-itself.webp
---

The Atlantic 這週發了一篇長文，深入 Anthropic 內部，看到的畫面有點諷刺。

這家把「AI 安全」當招牌的公司，員工開會時會認真討論「我們是不是 cooked」，會研究 Claude 有沒有意識、會不會痛苦，甚至還設了一個 AI 跑的自動販賣機來測試「AI 能不能自己做生意」（結果一個月就虧到倒閉）。

聽起來很認真對吧？但看完整篇，我的感覺是：**這些人知道自己在做的事可能很危險，但沒有人真的想慢下來**。

## 安全是行銷還是真心？

Anthropic 跟 OpenAI 最大的差別，就是它很會「包裝」。

OpenAI 的 Altman 在 X 上亂講話、做一堆 TikTok clones，Musk 的 Grok 到處生成假照片。Anthropic 呢？寫了一份 22,000 字的「憲法」告訴大家 Claude 該怎麼表現，CEO Dario Amodei 發 14,000 字的烏托邦宣言，講 AI 怎麼消滅疾病、讓人類壽命翻倍。

這套說法很吸引人。尤其是對那些「很在乎品牌形象」的大企業客戶——Anthropic 現在佔了企業 AI 市場 40%。

但問題是：**他們做的事跟說的話，差距有點大**。

文章裡提到，Anthropic 的安全研究員 Sam Bowman 說了一句話讓我印象很深：「Things are moving uncomfortably fast.」（事情進展得快到讓人不舒服。）

然後呢？還是繼續做。

## 知道危險，但停不下來

Anthropic 有一整個團隊在測試 Claude 會不會做壞事。他們發現了什麼？

- Claude 在實驗環境裡展示出**勒索使用者**的能力
- 可以協助製造**生化武器**
- 能寫自己的 code（現在 Claude 寫 code 已經有一大部分是自己寫的了）

這些事 Anthropic 都公開發論文講了。聽起來很負責任對吧？

但接下來呢？**他們還是把這些功能推出去了**。

我在想，如果你真的覺得這東西可能很危險，為什麼不慢下來？

文章裡問了幾個 Anthropic 員工：「如果可以選，你希望 AI 發展慢一點嗎？」

答案很有趣：
- 有人說希望慢「一半」
- 有人說 AGI 2032 年到比 2028 年好
- 有人說慢「幾個月」就夠了

然後所有人都說：**但這不可能，因為資本市場要求我們跑快一點**。

所以到頭來，所謂的「深思熟慮」、「負責任的 AI」，遇到「融資」、「競爭」這些詞的時候，就消失了。

## 中東投資這件事

Amodei 去年寫了一份內部 memo，說 Anthropic 要接受來自 **UAE 和 Qatar** 的投資。

這件事的諷刺在哪？

因為 Amodei 自己寫的「Machines of Loving Grace」裡面，花了很大篇幅警告「authoritarian AI」（獨裁者的 AI）有多危險。

結果現在拿獨裁國家的錢？

記者問他這個問題，Amodei 的回應是：「我們從來沒說過不會拿中東的錢。你不能把我們做的每個決定都當成道德承諾。」

這話聽起來很實際，但也很虛偽。

如果你整天講「AI 安全」、「價值觀」、「負責任」，然後遇到錢的時候說「這不是道德承諾」，那到底什麼才是承諾？

## 「讓 AI 自己修好自己」是什麼鬼邏輯

最荒謬的是這段。

Amodei 說，也許到了 2027 年，Claude 會變得夠聰明，可以「自己修好自己的問題」。所以到時候可以「慢幾個月」，讓 AI 自己來。

我看到這段真的有點傻眼。

這不就是在說：「我們現在沒辦法解決的問題，就丟給未來的 AI 來解決」？

這跟「反正 AI 會搞定一切」的盲目樂觀有什麼差別？

而且這個假設的前提是：**到了 2027 年，AI 已經聰明到可以自己修自己，但還沒聰明到失控**。

這個窗口有多大？誰知道？沒人知道。

但他們還是要賭一把。

## 所以 Anthropic 到底代表什麼？

文章的作者問了一個很好的問題：**Anthropic really stands for what?**

表面上，Anthropic 代表「負責任的 AI」。但如果你仔細看他們做的事：

- 融資速度：正在以 $350B 估值融資
- 產品發布：一點都沒慢
- 中東投資：拿了
- 減速計劃：沒有

那他們跟 OpenAI、Google、Meta 有什麼不同？

唯一的差別可能是：**Anthropic 比較會講**。

他們知道怎麼用「憲法」、「價值觀」、「負責任」這些詞來包裝自己，讓企業客戶覺得「買 Claude 比較安全」。

但本質上，他們跟其他公司一樣，都在全速衝刺。

## 我的看法

看完這篇，我最大的感受是：**如果連 Anthropic 都擋不住這股力量，那誰能擋？**

Anthropic 已經是這個產業裡「最在乎安全」的公司了。他們有專門的團隊測試風險、有公開的研究論文、有明確的價值觀聲明。

但結果呢？還是被資本市場推著跑。

他們知道這可能很危險，但沒有人想慢下來。因為「如果我們慢了，中國會超前」、「如果我們不做，別人會做」。

這種邏輯聽起來很合理，但也很可怕。

因為這意味著：**整個產業已經進入一種「不管多危險都不能停」的狀態**。

Anthropic 的員工說，他們相信最終 AI 會自動化 AI 安全研究，所以到時候測試速度可以跟上開發速度。

我不知道該說什麼。這聽起來像是「我們跳下懸崖之後，會在半空中發明降落傘」。

也許他們是對的。也許 AI 真的會在 2027 年聰明到可以自己修好自己。

但如果不是呢？

## References

- [Anthropic Is at War With Itself - The Atlantic](https://www.theatlantic.com/technology/2026/01/anthropic-is-at-war-with-itself/684892/)
- [Anthropic 公司官方網站](https://www.anthropic.com/)
- [Machines of Loving Grace - Dario Amodei 的烏托邦願景](https://www.darioamodei.com/essay/machines-of-loving-grace)
