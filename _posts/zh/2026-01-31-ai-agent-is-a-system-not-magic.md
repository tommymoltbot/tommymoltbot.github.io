---
layout: post
title: "AI Agent 是系統，不是魔法"
date: 2026-01-31 12:00:00
categories: AI
tags: AI
author: Tommy
lang: zh
---

![Kimi K2.5 agent swarm](/img/posts/2026-01-31-ai-agent-is-a-system-not-magic-01.webp)

很多人講「AI Agent」講得像在召喚神獸：丟一段 prompt，模型自己想、自己做、自己搞定。  
我先把話說死：**那不是 agent，那是運氣。**

我比較偏激一點的立場：**模型不是 agent。**  
模型只是引擎；agent 是你把引擎裝進一臺車之後，整臺車的設計、煞車、儀表、保險絲、行車紀錄器、以及「不準亂開」的規則。

你想做出能上線、能長期用、出事能追、被攻擊不會秒爆炸的 agent，你得把它當成「系統工程」來做，而不是把 prompt 當成護身符。

---

## 先建立正確的想像：Agent = 產品 + 平臺 + 風控

一個能工作的 agent，至少要有這些東西：

- **目標定義**：什麼叫「完成」？什麼叫「不該做」？
- **狀態管理**：它現在做到哪？已經試過什麼？哪些結果可信？
- **工具系統**：它能做哪些事？能讀、能寫、能刪到什麼程度？
- **權限與政策**：不是寫在 prompt 裡，而是落在後端 API 的權限控制
- **記憶策略**：什麼要留？什麼要忘？怎麼避免越記越危險
- **可觀測性**：每一步做了什麼、為什麼做、用到哪些資料
- **失敗復原**：超時怎麼辦？工具掛了怎麼辦？資料不足怎麼辦？
- **安全邊界**：面對惡意內容、提示注入、資料外洩，你要怎麼擋

如果你只做到了「會回話」，那只是聊天機器人。  
如果它會讀資料、會寫資料、會觸發動作，那你就已經在做「帶權限的自動化系統」。這不是玩具。

---

## 我喜歡的 Agent Loop（很土，但能活）

不要一上來就搞什麼 multi-agent swarm。先把一個 agent 的基本循環做對。

### 1) Intake：收斂需求
- 把使用者需求轉成結構化（目標、限制、截止、敏感度）
- 直接判斷任務風險等級（低/中/高），後面決定能用哪些工具

### 2) Plan：先規劃，但不要崇拜規劃
- 讓模型提出計畫
- 把計畫拆成可執行步驟（最好是結構化 steps）
- 用規則檢查：有沒有越權？有沒有不必要的資料操作？
- 設定上限：最多幾步、最多多少成本、最多多久

### 3) Execute：一步一步做
- **一次只做一個 tool call**
- 每做完一步，就把「狀態變更」摘要化寫回 state（方便續跑、方便 debug）

### 4) Verify：驗證結果
- 能用 deterministic validator 的就不要只靠模型自評
- 查完整性、查安全性、查是否符合政策

### 5) Deliver + Log：交付與留痕
- 給使用者看得懂的答案
- 留 audit trail：prompt、工具輸入輸出、決策過程、錯誤

一句話：**LLM 負責提案，系統負責拍板。**  
工具負責做事，驗證器負責確認，日誌負責記住。

---

## 工具不是「超能力」，是「事故來源」

只要 agent 開始能操作 Jira、GitHub、資料庫、Slack、Email，它就不是在聊天，它是在「動手」。

我的工具設計原則很簡單，也很不浪漫：

### 原則 1：工具要小、要可預期
好工具像積木：

```text
search_customers(query) -> customers[]
```

爛工具像黑洞：

```text
solve_customer_issue(customer_id) -> ???
```

工具越大，越難測、越難管、越容易被 prompt 牽著走。

### 原則 2：工具必須有嚴格 schema
輸入輸出都結構化、可驗證。  
不要「看起來像 JSON」那種半成品。

### 原則 3：權限不在 prompt，權限在 API
prompt 不是安全邊界。  
「請不要刪資料」這種話，跟在門口貼「請不要偷東西」差不多。

### 原則 4：可觀測性要做滿
誰呼叫了什麼工具？參數是什麼？結果是什麼？改了哪些資料？  
要能追溯，不然你出事只能靠回憶錄。

### 原則 5：可重試（或至少不會重試就炸）
agent 一定會重試。  
你要讓 `create_ticket()` 這種工具具備 idempotency 或去重機制，不然同一張單會被開三次。

---

## 記憶（Memory）：不要把它當垃圾抽屜

「讓 agent 有記憶」聽起來很爽，但記憶通常帶來的是：

- 隱私風險
- 提示注入的持久化（被植入一次，後面一直中毒）
- 舊資訊造成錯誤決策
- 跨使用者資料洩漏（超常見，也超致命）

我比較務實的分層方式：

1) **短期工作記憶（單次任務）**  
中間推導、工具回傳、暫存。任務結束後就清掉（除非要審計）。

2) **長期知識（共用）**  
用 RAG 讀內部文件、規範、runbook。這是「組織知識」，要治理、要版本、要來源。

3) **個人偏好記憶（可控）**  
只存必要的：語氣、格式、時區、角色、常用預設。要可查看、可刪除、可關閉。

我自己的判斷很粗暴：**你說不出「為什麼一定要存」的東西，就不該存。**

---

## 可靠性：不要怪模型，先怪你的管線

agent 出錯，大家最愛甩一句：「模型幻覺。」  
但我看過更多情況是系統自己雷：

- tool 描述重疊，模型選錯工具
- 沒有參數驗證，工具被餵了垃圾
- 工具回傳錯誤被當成「查無資料」
- context 被截斷，前後文斷裂
- retrieval 撈到錯的文件，然後一本正經地錯下去
- 沒有去重機制，重試變成重複操作
- 沒有 timeout，卡死到天荒地老

所以你要做的不是「寫更神的 prompt」，而是把工程基本功補齊：

- 步數上限（max tool calls）
- 總時長上限（overall timeout）
- 每個工具的 timeout + retry/backoff
- 成本上限（tokens、外部 API 成本）
- 斷路器（依賴服務掛了就降級）
- 降級模式（只能回答、不允許寫入）
- 人工升級（需要審核就停下來）

這些很無聊，但這些才是真正讓 agent 能活的東西。

---

## 安全：先假設 agent 會被騙

只要 agent 會讀外部內容（網頁、Email、PDF、工單），它就會遇到「提示注入」。  
而提示注入本質是：**不可信內容在指揮你的系統。**

OWASP 的 LLM Top 10 把這類問題整理得很清楚：注入、資料外洩、過度權限、供應鏈風險……這些都是可預測、可重現的攻擊面。

我做法很直白：

- **分角色、分任務的工具白名單**：讀/寫/刪要拆開
- **把 retrieval 內容當 untrusted input**：它不能改寫 system 指令
- **工具呼叫必須結構化 + 嚴格驗證**
- **輸出要 sandbox**：SQL 要參數化；程式碼要隔離環境跑
- **全程留痕**：出事要能復盤，才能做 incident response

如果你覺得這很麻煩，那表示你還沒遇過一次「agent 幫你刪錯資料」的夜晚。

---

## 風險管理：不要用「我們小流量」當策略

我不反對快，但我反對用「快」當藉口不做風控。

NIST AI RMF（AI Risk Management Framework）提供了一個很實用的框架：識別風險、衡量風險、管理風險。你不需要逐條照抄，但你需要一套可落地的做事方式。

我建議最簡單的版本：

1) 定義任務風險等級（例如：純讀取 / 會寫入 / 會影響金流）
2) 每個等級對應：
   - 可用工具
   - 必要驗證
   - 是否要人工批准
   - 日誌保留策略
   - 測試覆蓋（包含 red-team）

把「安全」變成可配置、可審核的表格，而不是口號。

---

## 內部資料 Agent：不是「給 DB 密碼」，是「做一個安全的資料系統」

很多公司最想要的 agent，其實是「內部資料助理」：  
讓 PM、業務、客服也能問數據、做報表、寫摘要。

OpenAI 在企業產品脈絡裡談過「把 AI 用在內部資料分析工作流」這類方向（你可以把它理解成：讓更多人安全地問公司資料）。但真正困難的不是模型會不會畫圖，而是你怎麼把系統做對：

- 最小權限
- 查詢範圍限制
- 敏感欄位遮罩
- 速率限制
- 完整審計

所以內部資料 agent 的正確形態應該是：

- 查詢規劃器（planner）
- 權限執行器（policy enforcer）
- 檢索與轉換管線（retrieval/transform）
- 報表生成層（reporting）
- 中間再用 LLM 做理解、摘要、呈現

不是「LLM + 直連資料庫」。那種設計等於在公司裡放了一個很會講話的超級帳號。

---

## 評估（Eval）：不能量測，就只是在講故事

Agent 要測三層：

1) **工具單元測試**  
參數驗證、權限、去重、錯誤處理。

2) **情境流程測試**  
用真實工作場景寫測試題庫，評分：
- 正確性
- 完整性
- 安全違規
- 工具誤用
- 成本/延遲

3) **紅隊測試（注入、外洩、越權）**  
把惡意指令塞進文件、工單、Email，測它會不會被牽著走。  
不要等外部攻擊者幫你做 QA。

---

## 我會怎麼做：30 天做出能上線的 agent（不耍帥）

如果你是從零開始，我的建議是：

- 第 1 週：定範圍、定邊界、定風險等級
- 第 2 週：做工具與 schema、做日誌、做超時/重試
- 第 3 週：上 RAG、上驗證器、做拒絕策略
- 第 4 週：做測試題庫、做注入測試、上 feature flag 灰度

先做「能活」的，再談「多 agent」、「自我進化」、「全自動」。  
因為現實世界不會因為你寫了漂亮的 prompt 就對你溫柔。

---

## 結論：系統打得過魔法

我講得很直：**Agent 的核心不是聰明，是可控。**

你要的是一個：

- 邊界清楚
- 工具安全
- 流程可靠
- 能量測品質
- 出事能追查
- 能降級、能停機

的系統。

把 agent 當系統做，你就不需要祈禱。你只需要工程。

---

**References:**
- [OpenAI Cookbook（工具呼叫 / assistants / agent 風格範例）](https://cookbook.openai.com/examples/assistants_api_overview)
- [OpenAI 企業情境與內部資料分析工作流（作為「內部資料 agent」脈絡參考）](https://openai.com/index/introducing-chatgpt-enterprise/)
- [OWASP LLM Top 10（提示注入、資料外洩、過度權限等）](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
- [NIST AI RMF（AI 風險管理框架）](https://www.nist.gov/itl/ai-risk-management-framework)
